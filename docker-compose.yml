version: "3.9"

services:
  backend:
    build:
      context: ./backend
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    env_file:
      - ./backend/.env.example
    volumes:
      - ./backend:/app
    depends_on:
      - db

  frontend:
    build:
      context: ./frontend
    command: pnpm dev --host --port 3000
    ports:
      - "3000:3000"
    env_file:
      - ./frontend/.env.example
    volumes:
      - ./frontend:/app
    depends_on:
      - backend

  db:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: keiba
      POSTGRES_USER: keiba
      POSTGRES_PASSWORD: keiba
    volumes:
      - db-data:/var/lib/postgresql/data

  ml-worker:
    build:
      context: ./ml
    command: python -m ml.worker
    volumes:
      - ./ml:/app
    depends_on:
      - db

  ml-inference:
    build:
      context: .
      dockerfile: ml/Dockerfile
    command: python -m ml.inference.server
    ports:
      - "8001:8001"
    env_file:
      - ./backend/.env.example
    volumes:
      - ./ml:/app/ml
      - ./backend/app:/app/app
      - ./ml/artifacts:/app/ml/artifacts
    depends_on:
      - db
    environment:
      - DATABASE_URL=postgresql://keiba:keiba@db:5432/keiba

  scheduler:
    build:
      context: ./backend
    command: python -m app.tasks.scheduler_main
    env_file:
      - ./backend/.env.example
    volumes:
      - ./backend:/app
    depends_on:
      - db
      - backend
    environment:
      - DATABASE_URL=postgresql://keiba:keiba@db:5432/keiba

volumes:
  db-data:

