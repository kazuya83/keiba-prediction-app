# 実行計画 09: 予測実行APIとジョブ制御

## ゴール
- 予測処理をAPI経由で実行し、機械学習モデルに対する推論リクエスト/結果返却を実装する。

## 手順
1. `backend/app/services/prediction_runner.py` を作成し、機械学習モデル推論を行うサービスクラスを実装（同期/非同期方式を決定）。
2. 予測リクエスト用スキーマ（レースID、使用する特徴量設定）を `backend/app/schemas/prediction_request.py` に追加。
3. `backend/app/api/routers/predictions.py` に `POST /api/predictions` を実装し、ジョブIDを返却。処理時間が1分以内に収まるか検証。
4. 推論処理をCeleryやRQなどのキューワーカーに委譲する場合、`worker` コンテナとタスク定義を追加。
5. 推論結果を `Prediction` テーブルに保存し、結果取得API（計画08で実装済み）から参照可能にする。
6. 推論根拠表示のため、特徴量重要度やSHAP値などの情報をサービス層で計算し、レスポンスに含める。
7. `backend/tests/services/test_prediction_runner.py` とAPI統合テストで、正常系・タイムアウト・エラー時再試行を検証。

## 成果物
- 推論実行APIが動作し、ジョブIDまたは即時レスポンスが返る。
- 推論結果がDBに保存され、履歴API経由で閲覧可能。
- 推論根拠がレスポンスに含まれ、テストで保証。

## 依存・前提
- 計画08までの予測履歴/統計処理が完了し、Predictionテーブルが利用可能。
- MLモデルのインターフェース仕様（計画14〜15で整備予定）が共有されている。

## リスクと対策
- **リスク**: 推論時間が1分を超える。  
  **対策**: 前処理キャッシュ、モデル軽量化、非同期ジョブ化を検討。
- **リスク**: ワーカー障害による処理失敗。  
  **対策**: リトライ設定と失敗ジョブの再実行APIを用意。

